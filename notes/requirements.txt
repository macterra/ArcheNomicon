I will publish short stories set in the future when the System has more features
the stories will feature well-defined characters (xidb users) and describe how the System 
solves a real world problem,

Different stories using the same hypothetical new features to solve different problems can be used to build up a histogram of risk vs VaR which can be used to estimate the value of the feature.

Eventually a team of product managers will write the SF requirements,
all set in the same world (maybe) and using the same characters and organizations (agents).

The stories can be elaborated as needed by revising with links to explanatory content.
For example, mentioning ancient agents from the early 21st century such as Microsoft and Bill Gates
can be linked to wikipedia-like pages.
Moreover any interested party can publish a comment on a clip from the story in order to discuss the meaning.

These stories will act as fodder for formal feature proposals for the System.

Eventually any user will be able to contribute SF/req stories (of course nothing is ever preventing them from doing so).

The difference is that we will have an endorsement system in place. 

Say only a small team has access to the formal feature backlog for the ArcheTech system,
presumably software professionals on staff at ArcheTech Corp.
But this core team may have a formal relationship with a steering committee composed of large corporations with vested interests in the System (customers, partners, etc).
In turn, the members of the steering committees may seek advice from wider groups, and so on.
Eventually almost everyone will know someone that can endorse their SF/req story and recommend it to someone else closer to the team with authority to make it happen.

Likewise anyone can "make it happen" for their own private fork of the System. 
That may cost a lot more (to develop the features) but it will then be easier to convince ArcheTech to pull the changeset back into the mainline so the new feature is available to all outside the developer.
Of course the developer has to decide if the value of doing so outweighs whatever costs are realized by giving away the feature to all (essentially public domain like everything in The Vault), i.e. they may be unable to sell it when it is available for free)

--

first story idea

courtroom drama set 100 years from now
one company is suing another in a lawsuit worth billions (in 2013$)
key evidence is in the Vault but when they try to retrieve it they get an error(!)
saying that the content is safe and sound but in order to deliver it you must purchase a key from Microsoft Corp.

a protagonist (maybe the jr lawyer) had never heard of this before and she is outraged
how can this happen? I thought everything in the vault is public domain!
more knowledgeable protagonist explains
that is basically true, but back in the early days of ArcheTech a lot of content was generated on proprietary systems. 
In order to run the xidb scripts, it was necessary to load of vm containing proprietary software.
So if the Documents are garbage collected due to zero access for an extended time then they
will have to be regenerated by running the script which legally requires a license.

yl: but surely we could bypass it, write a script that delivers the same content without legal restrictions?
ol: yes, and we still might. But if we want to follow the law and honour the agreements we swore to as users of the System, we have to follow up and determine how much it will cost to acquire a key to unlock the Document.
You've heard of Microsoft, right?
yl: Of course! Isn't that how Bill Gates made his fortune around the turn of the 21st centure? 
ol: That's right, but do you remember what became of Microsoft?
yl: No, it never occurred to me. They haven't been in the news for decades.
ol: I seem to remember that they were acquired back in the 50s but I don't remember the details.

[describe how the lawyers use the System to track down the legal heir of Microsoft through a fictional future history of technology company mergers and acquisitions

in a twist it turns out that Archetech itself is the legal heir since it partnered with Microsoft's heir.

The cost of key turns out to be the cost of a 2-day custom engineering project that Archetech provides.
ArcheTech is *very* expensive to hire, but the job will cost $1million 

The lawyers take that to their clients, who agree that the $1million is a bargain to ensure that the case is not lost.

Maybe they know that the case is ensured if they can access the Document because they already know what the Document contains, they just need to prove when it was published, making use of the System's notary service.

Archetech releases a press/marketing statement announcing this case.
The President of ArcheTech is quoted as saying that this was a great outcome for all involved.
The System was able to help the client win the legal case by proving beyond a reasonable doubt
that the plaintiff? had precedent.
And it was a great outcome for ArcheTech, we were able to prove to ourselves and others that we have the systems and processes in place to retrieve long lost Documents of value.
Lastly the President would like to thank Microsoft for having the foresight to license their software to Archetech for just such a contingency. 
It is true that when the agreement was signed, piracy was still a major problem for proprietary software companies. 
Licensing the software to Archetech possibly made it more convenient for pirates to access it but the truth was that refusing to do so wouldn't have stopped anyone. All the software was already freely available on Bit Torrent and Mega.com, Archetech was just a faster download.
But because Microsoft took that risk, we Microsoft's future partners benefited.

elaborate on 

	* how content is generated from Document scripts
	* how content is cached and can be garbage collected
	* how content is published
	* 
		* publisher runs Document script and saves output (content)
		* publisher computes hash of content
		* publisher submits Document and hash to the System
		* System runs Document and save output
		* System computes hash and ensures hash is identical to one publisher passed
		* System verifies Document (metadata, valid links, content format, etc)
		* If everything checks out the adds timestamp and content hash to head and notarizes (signs) the Document
		* Document and Content are cached
		* Content may be garbage collected but Document can't be
		* System passes back hash of signed, verified, timestamped Document and Content
		* Publisher compares Content to ensure it is identical
		* Publisher stores hash (ID) of Document in local storage for future access



<head>
     <URI>/ScriptID/DocID</URI>
     <publisher/>
     <authors/>
     <timestamp/>
</head>
<body>
</body>

script ID is Program Document that tells how to run script interpreter
input to program is ID of script







